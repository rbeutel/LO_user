{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting model \"cast\" files into one dataframe with depth matched to observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gsw\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/data1/bbeutel/LO_output/extract_cast/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: despite units being g/kg, the model salinity is practical salinity!\n",
    "### source: https://github.com/parkermac/LPM/blob/main/obsmod/process_multi_ctd.py line 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfo_ctd(year):    \n",
    "\n",
    "    dfo = pd.read_pickle('/data1/parker/LO_output/obs/dfo1/ctd/'+str(year)+'.p')\n",
    "\n",
    "    dfo['h'] = np.nan\n",
    "    dfo['z_model'] = np.nan\n",
    "    dfo['SA_model'] = np.nan\n",
    "    dfo['CT_model'] = np.nan\n",
    "    dfo['DO_model'] = np.nan\n",
    "    cid = np.arange(0,int(np.max(dfo.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"dfo1_ctd_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            # print(i)\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "            dfo.h[dfo.cid == i] = cast.h\n",
    "            dfo.z_model[dfo.cid == i] = np.array([nearest(cast.h*cast.s_rho,dfo.z[dfo.cid == i][j]) \n",
    "                                                        for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            PT = np.array([cast.temp[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            SP = np.array([cast.salt[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.DO_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "\n",
    "            dfo.SA_model[dfo.cid == i] = gsw.SA_from_SP(SP, np.array(dfo.z[dfo.cid == i]*-1), np.array(dfo.lon[dfo.cid == i]), np.array(dfo.lat[dfo.cid == i]))\n",
    "            dfo.CT_model[dfo.cid == i] = gsw.CT_from_pt(dfo.SA_model[dfo.cid == i], PT)\n",
    "\n",
    "    name = \"dfo_ctd_\"+str(year)+\".csv\"\n",
    "    dfo.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_dfo_ctd(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfo_bottle(year):    \n",
    "\n",
    "    dfo = pd.read_pickle('/data1/parker/LO_output/obs/dfo1/bottle/'+str(year)+'.p').drop(axis=1,labels=['name','cruise']).dropna()\n",
    "\n",
    "    dfo['h'] = np.nan\n",
    "    dfo['z_model'] = np.nan\n",
    "    dfo['SA_model'] = np.nan\n",
    "    dfo['CT_model'] = np.nan\n",
    "    dfo['DO_model'] = np.nan\n",
    "    dfo['NO3_model'] = np.nan\n",
    "\n",
    "    cid = np.arange(0,int(np.max(dfo.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"dfo1_bottle_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "\n",
    "            dfo.h[dfo.cid == i] = cast.h\n",
    "            dfo.z_model[dfo.cid == i] = np.array([nearest(cast.h*cast.s_rho,dfo.z[dfo.cid == i][j]) \n",
    "                                                        for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            PT = np.array([cast.temp[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            SP = np.array([cast.salt[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.DO_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.NO3_model[dfo.cid == i] = np.array([cast.NO3[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            # dfo.Chl_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model)]])\n",
    "                    # dont really know what to do with Chl yet but might as well take it\n",
    "\n",
    "\n",
    "            dfo.SA_model[dfo.cid == i] = gsw.SA_from_SP(SP, np.array(dfo.z[dfo.cid == i]*-1), np.array(dfo.lon[dfo.cid == i]), np.array(dfo.lat[dfo.cid == i]))\n",
    "            dfo.CT_model[dfo.cid == i] = gsw.CT_from_pt(dfo.SA_model[dfo.cid == i], PT)\n",
    "\n",
    "    name = \"dfo_botte_\"+str(year)+\".csv\"\n",
    "    dfo.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cid</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>z</th>\n",
       "      <th>SA</th>\n",
       "      <th>CT</th>\n",
       "      <th>DO (uM)</th>\n",
       "      <th>NO3 (uM)</th>\n",
       "      <th>Chl (mg m-3)</th>\n",
       "      <th>h</th>\n",
       "      <th>z_model</th>\n",
       "      <th>SA_model</th>\n",
       "      <th>CT_model</th>\n",
       "      <th>DO_model</th>\n",
       "      <th>NO3_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-126.3340</td>\n",
       "      <td>48.624500</td>\n",
       "      <td>2017-02-07 14:50:45</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>32.698785</td>\n",
       "      <td>9.202596</td>\n",
       "      <td>282.23343</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.57</td>\n",
       "      <td>735.887373</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.862832</td>\n",
       "      <td>9.055119</td>\n",
       "      <td>270.132965</td>\n",
       "      <td>13.084056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-126.6655</td>\n",
       "      <td>48.651333</td>\n",
       "      <td>2017-02-07 22:43:09</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>32.438786</td>\n",
       "      <td>9.175869</td>\n",
       "      <td>284.46628</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1307.365892</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.783173</td>\n",
       "      <td>9.077599</td>\n",
       "      <td>271.404907</td>\n",
       "      <td>12.221288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-126.6655</td>\n",
       "      <td>48.651333</td>\n",
       "      <td>2017-02-07 22:43:09</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>32.493155</td>\n",
       "      <td>9.195749</td>\n",
       "      <td>284.46628</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1307.365892</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.783104</td>\n",
       "      <td>9.077600</td>\n",
       "      <td>271.404907</td>\n",
       "      <td>12.221288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-126.6655</td>\n",
       "      <td>48.651333</td>\n",
       "      <td>2017-02-07 22:43:09</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>32.512463</td>\n",
       "      <td>9.170014</td>\n",
       "      <td>284.46628</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1307.365892</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.783039</td>\n",
       "      <td>9.077601</td>\n",
       "      <td>271.404907</td>\n",
       "      <td>12.221288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-126.6655</td>\n",
       "      <td>48.651333</td>\n",
       "      <td>2017-02-07 22:43:09</td>\n",
       "      <td>-14.7</td>\n",
       "      <td>32.516979</td>\n",
       "      <td>9.159109</td>\n",
       "      <td>284.01970</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1307.365892</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.783026</td>\n",
       "      <td>9.077601</td>\n",
       "      <td>271.404907</td>\n",
       "      <td>12.221288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  cid       lon        lat                 time     z         SA  \\\n",
       "0           0  0.0 -126.3340  48.624500  2017-02-07 14:50:45  -5.9  32.698785   \n",
       "1          46  3.0 -126.6655  48.651333  2017-02-07 22:43:09  -1.5  32.438786   \n",
       "2          49  3.0 -126.6655  48.651333  2017-02-07 22:43:09  -5.9  32.493155   \n",
       "3          50  3.0 -126.6655  48.651333  2017-02-07 22:43:09 -10.0  32.512463   \n",
       "4          51  3.0 -126.6655  48.651333  2017-02-07 22:43:09 -14.7  32.516979   \n",
       "\n",
       "         CT    DO (uM)  NO3 (uM)  Chl (mg m-3)            h  z_model  \\\n",
       "0  9.202596  282.23343       5.9          0.57   735.887373     29.0   \n",
       "1  9.175869  284.46628       5.3          0.87  1307.365892     29.0   \n",
       "2  9.195749  284.46628       5.4          0.73  1307.365892     29.0   \n",
       "3  9.170014  284.46628       5.4          0.82  1307.365892     29.0   \n",
       "4  9.159109  284.01970       5.5          0.70  1307.365892     29.0   \n",
       "\n",
       "    SA_model  CT_model    DO_model  NO3_model  \n",
       "0  32.862832  9.055119  270.132965  13.084056  \n",
       "1  32.783173  9.077599  271.404907  12.221288  \n",
       "2  32.783104  9.077600  271.404907  12.221288  \n",
       "3  32.783039  9.077601  271.404907  12.221288  \n",
       "4  32.783026  9.077601  271.404907  12.221288  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('dfo_botte_2017.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ncei(CoastalSalish, year):    \n",
    "\n",
    "    d = pd.read_pickle('/data1/parker/LO_output/obs/ncei'+CoastalSalish+'/bottle/'+str(year)+'.p').drop(axis=1,labels=['name','cruise'])#.dropna()\n",
    "    d['h'] = np.nan\n",
    "    d['z_model'] = np.nan\n",
    "    d['SA_model'] = np.nan\n",
    "    d['CT_model'] = np.nan\n",
    "    d['DO_model'] = np.nan\n",
    "    d['NO3_model'] = np.nan\n",
    "    d['TIC_model'] = np.nan\n",
    "    d['TA_model'] = np.nan\n",
    "\n",
    "\n",
    "    cid = np.arange(0,int(np.max(d.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"ncei\"+CoastalSalish+\"_bottle_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            # print(files[i][0])\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "\n",
    "            d.h[d.cid == i] = cast.h\n",
    "            d.z_model[d.cid == i] = np.array([nearest(cast.h*cast.s_rho,d.z[d.cid == i][j]) \n",
    "                                                        for j in np.array(d[d.cid == i].index)])\n",
    "            PT = np.array([cast.temp[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            SP = np.array([cast.salt[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.DO_model[d.cid == i] = np.array([cast.oxygen[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.NO3_model[d.cid == i] = np.array([cast.NO3[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.TIC_model[d.cid == i] = np.array([cast.TIC[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.TA_model[d.cid == i] = np.array([cast.alkalinity[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "\n",
    "    \n",
    "            d.SA_model[d.cid == i] = gsw.SA_from_SP(np.array(SP), np.array(d.z[d.cid == i]*-1), np.array(d.lon[d.cid == i]), np.array(d.lat[d.cid == i]))\n",
    "            d.CT_model[d.cid == i] = gsw.CT_from_pt(d.SA_model[d.cid == i], PT)\n",
    "\n",
    "    name = \"ncei\"+CoastalSalish+\"_\"+str(year)+\".csv\"\n",
    "    d.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LObecca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
