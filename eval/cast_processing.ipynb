{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting model \"cast\" files into one dataframe with depth matched to observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gsw\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/data1/bbeutel/LO_output/extract_cast/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfo_ctd(year):    \n",
    "\n",
    "    dfo = pd.read_pickle('/data1/parker/LO_output/obs/dfo1/ctd/'+str(year)+'.p')\n",
    "\n",
    "    dfo['h'] = np.nan\n",
    "    dfo['z_model'] = np.nan\n",
    "    dfo['PT_model'] = np.nan\n",
    "    dfo['SA_model'] = np.nan\n",
    "    dfo['CT_model'] = np.nan\n",
    "    dfo['DO_model'] = np.nan\n",
    "    cid = np.arange(0,int(np.max(dfo.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"dfo1_ctd_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            # print(i)\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "            dfo.h[dfo.cid == i] = cast.h\n",
    "            dfo.z_model[dfo.cid == i] = np.array([nearest(cast.h*cast.s_rho,dfo.z[dfo.cid == i][j]) \n",
    "                                                        for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.PT_model[dfo.cid == i] = np.array([cast.temp[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.SA_model[dfo.cid == i] = np.array([cast.salt[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.DO_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "\n",
    "\n",
    "    dfo.CT_model = gsw.CT_from_pt(dfo.SA_model, dfo.PT_model)\n",
    "\n",
    "    name = \"dfo_ctd_\"+str(year)+\".csv\"\n",
    "    dfo.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_dfo_ctd(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfo_bottle(year):    \n",
    "\n",
    "    dfo = pd.read_pickle('/data1/parker/LO_output/obs/dfo1/bottle/'+str(year)+'.p').drop(axis=1,labels=['name','cruise']).dropna()\n",
    "\n",
    "    dfo['h'] = np.nan\n",
    "    dfo['z_model'] = np.nan\n",
    "    dfo['PT_model'] = np.nan\n",
    "    dfo['SA_model'] = np.nan\n",
    "    dfo['CT_model'] = np.nan\n",
    "    dfo['DO_model'] = np.nan\n",
    "    dfo['NO3_model'] = np.nan\n",
    "\n",
    "    cid = np.arange(0,int(np.max(dfo.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"dfo1_bottle_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "\n",
    "            dfo.h[dfo.cid == i] = cast.h\n",
    "            dfo.z_model[dfo.cid == i] = np.array([nearest(cast.h*cast.s_rho,dfo.z[dfo.cid == i][j]) \n",
    "                                                        for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.PT_model[dfo.cid == i] = np.array([cast.temp[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.SA_model[dfo.cid == i] = np.array([cast.salt[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.DO_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.NO3_model[dfo.cid == i] = np.array([cast.NO3[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            # dfo.Chl_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model)]])\n",
    "                    # dont really know what to do with Chl yet but might as well take it\n",
    "\n",
    "\n",
    "    dfo.CT_model = gsw.CT_from_pt(dfo.SA_model, dfo.PT_model)\n",
    "\n",
    "    name = \"dfo_botte_\"+str(year)+\".csv\"\n",
    "    dfo.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ncei(CoastalSalish, year):    \n",
    "\n",
    "    d = pd.read_pickle('/data1/parker/LO_output/obs/ncei'+CoastalSalish+'/bottle/'+str(year)+'.p').drop(axis=1,labels=['name','cruise'])#.dropna()\n",
    "    d['h'] = np.nan\n",
    "    d['z_model'] = np.nan\n",
    "    d['PT_model'] = np.nan\n",
    "    d['SA_model'] = np.nan\n",
    "    d['CT_model'] = np.nan\n",
    "    d['DO_model'] = np.nan\n",
    "    d['NO3_model'] = np.nan\n",
    "    d['TIC_model'] = np.nan\n",
    "    d['TA_model'] = np.nan\n",
    "\n",
    "\n",
    "    cid = np.arange(0,int(np.max(d.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"ncei\"+CoastalSalish+\"_bottle_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            # print(files[i][0])\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "\n",
    "            d.h[d.cid == i] = cast.h\n",
    "            d.z_model[d.cid == i] = np.array([nearest(cast.h*cast.s_rho,d.z[d.cid == i][j]) \n",
    "                                                        for j in np.array(d[d.cid == i].index)])\n",
    "            d.PT_model[d.cid == i] = np.array([cast.temp[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.SA_model[d.cid == i] = np.array([cast.salt[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.DO_model[d.cid == i] = np.array([cast.oxygen[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.NO3_model[d.cid == i] = np.array([cast.NO3[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.TIC_model[d.cid == i] = np.array([cast.TIC[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.TA_model[d.cid == i] = np.array([cast.alkalinity[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "\n",
    "    d.CT_model = gsw.CT_from_pt(d.SA_model, d.PT_model)\n",
    "\n",
    "    name = \"ncei\"+CoastalSalish+\"_\"+str(year)+\".csv\"\n",
    "    d.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ncei('Salish', 2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ncei('Salish', 2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LObecca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
