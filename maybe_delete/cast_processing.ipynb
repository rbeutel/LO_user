{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting model \"cast\" files into one dataframe with depth matched to observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gsw\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/data1/bbeutel/LO_output/extract_cast/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: despite units being g/kg, the model salinity is practical salinity!\n",
    "### source: https://github.com/parkermac/LPM/blob/main/obsmod/process_multi_ctd.py line 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfo_ctd(year):    \n",
    "\n",
    "    dfo = pd.read_pickle('/data1/parker/LO_output/obs/dfo1/ctd/'+str(year)+'.p')\n",
    "\n",
    "    dfo['h'] = np.nan\n",
    "    dfo['z_model'] = np.nan\n",
    "    dfo['SA_model'] = np.nan\n",
    "    dfo['CT_model'] = np.nan\n",
    "    dfo['DO_model'] = np.nan\n",
    "    dfo['Chl_model'] = np.nan\n",
    "\n",
    "    cid = np.arange(0,int(np.max(dfo.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"dfo1_ctd_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            # print(i)\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "            dfo.h[dfo.cid == i] = cast.h\n",
    "            dfo.z_model[dfo.cid == i] = np.array([nearest(cast.h*cast.s_rho,dfo.z[dfo.cid == i][j]) \n",
    "                                                        for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            PT = np.array([cast.temp[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            SP = np.array([cast.salt[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.DO_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.Chl_model[dfo.cid == i] = np.array([cast.phytoplankton[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "\n",
    "            P = gsw.p_from_z(np.array(dfo.z[dfo.cid == i]*-1), np.array(dfo.lat[dfo.cid == i]))\n",
    "            dfo.SA_model[dfo.cid == i] = gsw.SA_from_SP(SP, P, np.array(dfo.lon[dfo.cid == i]), np.array(dfo.lat[dfo.cid == i]))\n",
    "            dfo.CT_model[dfo.cid == i] = gsw.CT_from_pt(dfo.SA_model[dfo.cid == i], PT)\n",
    "\n",
    "    name = \"dfo_ctd_\"+str(year)+\".csv\"\n",
    "    dfo.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_dfo_ctd(2018)\n",
    "# read_dfo_ctd(2019)\n",
    "# read_dfo_ctd(2020)\n",
    "# read_dfo_ctd(2021)\n",
    "# read_dfo_ctd(2017)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfo_bottle(year):    \n",
    "\n",
    "    dfo = pd.read_pickle('/data1/parker/LO_output/obs/dfo1/bottle/'+str(year)+'.p').drop(axis=1,labels=['name','cruise']).dropna()\n",
    "\n",
    "    dfo['h'] = np.nan\n",
    "    dfo['z_model'] = np.nan\n",
    "    dfo['SA_model'] = np.nan\n",
    "    dfo['CT_model'] = np.nan\n",
    "    dfo['DO_model'] = np.nan\n",
    "    dfo['NO3_model'] = np.nan\n",
    "    dfo['Chl_model'] = np.nan\n",
    "\n",
    "\n",
    "    cid = np.arange(0,int(np.max(dfo.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"dfo1_bottle_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "\n",
    "            dfo.h[dfo.cid == i] = cast.h\n",
    "            dfo.z_model[dfo.cid == i] = np.array([nearest(cast.h*cast.s_rho,dfo.z[dfo.cid == i][j]) \n",
    "                                                        for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            PT = np.array([cast.temp[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            SP = np.array([cast.salt[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.DO_model[dfo.cid == i] = np.array([cast.oxygen[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.NO3_model[dfo.cid == i] = np.array([cast.NO3[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "            dfo.Chl_model[dfo.cid == i] = np.array([cast.phytoplankton[int(dfo.z_model[j])] for j in np.array(dfo[dfo.cid == i].index)])\n",
    "\n",
    "            P = gsw.p_from_z(np.array(dfo.z[dfo.cid == i]*-1), np.array(dfo.lat[dfo.cid == i]))\n",
    "            dfo.SA_model[dfo.cid == i] = gsw.SA_from_SP(SP, P, np.array(dfo.lon[dfo.cid == i]), np.array(dfo.lat[dfo.cid == i]))\n",
    "            dfo.CT_model[dfo.cid == i] = gsw.CT_from_pt(dfo.SA_model[dfo.cid == i], PT)\n",
    "\n",
    "    name = \"dfo_botte_\"+str(year)+\".csv\"\n",
    "    dfo.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dfo_bottle(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ncei(CoastalSalish, year):    \n",
    "\n",
    "    d = pd.read_pickle('/data1/parker/LO_output/obs/ncei'+CoastalSalish+'/bottle/'+str(year)+'.p').drop(axis=1,labels=['name','cruise'])#.dropna()\n",
    "    d['h'] = np.nan\n",
    "    d['z_model'] = np.nan\n",
    "    d['SA_model'] = np.nan\n",
    "    d['CT_model'] = np.nan\n",
    "    d['DO_model'] = np.nan\n",
    "    d['NO3_model'] = np.nan\n",
    "    d['TIC_model'] = np.nan\n",
    "    d['TA_model'] = np.nan\n",
    "    d['Chl_model'] = np.nan\n",
    "\n",
    "\n",
    "    cid = np.arange(0,int(np.max(d.cid))+1,1)\n",
    "\n",
    "    files = [sorted(path.glob(\"ncei\"+CoastalSalish+\"_bottle_{}/{}.nc\".format(year,str(cid[i])))) for i in range(len(cid))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if len(files[i]) == 1:\n",
    "            # print(files[i][0])\n",
    "            cast = xr.open_dataset(files[i][0])\n",
    "\n",
    "\n",
    "            d.h[d.cid == i] = cast.h\n",
    "            d.z_model[d.cid == i] = np.array([nearest(cast.h*cast.s_rho,d.z[d.cid == i][j]) \n",
    "                                                        for j in np.array(d[d.cid == i].index)])\n",
    "            PT = np.array([cast.temp[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            SP = np.array([cast.salt[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.DO_model[d.cid == i] = np.array([cast.oxygen[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.NO3_model[d.cid == i] = np.array([cast.NO3[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.TIC_model[d.cid == i] = np.array([cast.TIC[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.TA_model[d.cid == i] = np.array([cast.alkalinity[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "            d.Chl_model[d.cid == i] = np.array([cast.phytoplankton[int(d.z_model[j])] for j in np.array(d[d.cid == i].index)])\n",
    "\n",
    "            P = gsw.p_from_z(np.array(d.z[d.cid == i]*-1), np.array(d.lat[d.cid == i]))\n",
    "            d.SA_model[d.cid == i] = gsw.SA_from_SP(SP, P, np.array(d.lon[d.cid == i]), np.array(d.lat[d.cid == i]))\n",
    "            d.CT_model[d.cid == i] = gsw.CT_from_pt(d.SA_model[d.cid == i], PT)\n",
    "\n",
    "    name = \"ncei\"+CoastalSalish+\"_\"+str(year)+\".csv\"\n",
    "    d.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LObecca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
